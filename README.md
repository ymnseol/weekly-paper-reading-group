# ðŸ§‘â€ðŸŽ“ Weekly Paper Reading Group

This repository contains the summaries of papers related to the alignment problem in Natural Language Processing (NLP), and discussions with [Kyoungwhan Mheen](https://github.com/kwmheen357).  
All the summaries and discussions are either in Korean (í•œêµ­ì–´) or English.

## Description

### Objective

This covers several papers related to the alignment problem and the methods such as instruction tuning and Reinforcement Learning from Human Feedback (RLHF) that attempt to solve it.

### Papers

> You can click the document emoji (ðŸ“„) to read the summary if available.

| Title | Presented | Codes | Tag | Presenter |
|-------|:---------:|-------|-----|:---------:|
| [FLAN: Finetuned Language Models Are Zero-Shot Learners](https://arxiv.org/pdf/2109.01652.pdf) | âœ… [ðŸ“„](https://heliuminerte.notion.site/FLAN-Finetuned-Language-Models-Are-Zero-Shot-Learners-b33286ef61764fd6b18425a06356f42d) | [google-research/FLAN](https://github.com/google-research/FLAN) | `Instruction Tuning` | [Yumin Seol](https://github.com/ymnseol) |
| [T0: Multitask Prompted Training Enables Zero-Shot Task Generalization](https://arxiv.org/abs/2110.08207) | | [bigscience-workshop/t-zero](https://github.com/bigscience-workshop/t-zero) | | |
| [InstructGPT: Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155) | | | | |
| [Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862) | | [anthropics/hh-rlhf](https://github.com/anthropics/hh-rlhf) | | |
| [Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks](https://arxiv.org/abs/2204.07705) | | [allenai/natural-instructions](https://github.com/allenai/natural-instructions) | | |
| [Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners](https://arxiv.org/abs/2210.02969) | | [seonghyeonye/Flipped-Learning](https://github.com/seonghyeonye/Flipped-Learning) | | |
| [Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2210.11416) | |
| [Exploring the Benefits of Training Expert Language Models over Instruction Tuning](https://arxiv.org/abs/2302.03202) | | [joeljang/elm](https://github.com/joeljang/elm) | | |
